{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9bc2b73e",
   "metadata": {},
   "source": [
    "# Machine Learning Pipeline with GCP and FastAPI\n",
    "\n",
    "This notebook implements a complete ML pipeline that:\n",
    "1. Connects to GCP services for data ingestion\n",
    "2. Performs data preprocessing and cleaning\n",
    "3. Trains a regression model\n",
    "4. Serves predictions via FastAPI\n",
    "\n",
    "Let's start by installing the required packages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "37f99110",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: google-cloud-storage in ./.venv/lib/python3.12/site-packages (3.4.0)\n",
      "Requirement already satisfied: scikit-learn in ./.venv/lib/python3.12/site-packages (1.7.2)\n",
      "Requirement already satisfied: pandas in ./.venv/lib/python3.12/site-packages (2.3.2)\n",
      "Requirement already satisfied: numpy in ./.venv/lib/python3.12/site-packages (2.3.3)\n",
      "Requirement already satisfied: fastapi in ./.venv/lib/python3.12/site-packages (0.116.2)\n",
      "Requirement already satisfied: uvicorn in ./.venv/lib/python3.12/site-packages (0.35.0)\n",
      "Requirement already satisfied: python-dotenv in ./.venv/lib/python3.12/site-packages (1.1.1)\n",
      "Requirement already satisfied: google-auth<3.0.0,>=2.26.1 in ./.venv/lib/python3.12/site-packages (from google-cloud-storage) (2.40.3)\n",
      "Requirement already satisfied: google-api-core<3.0.0,>=2.15.0 in ./.venv/lib/python3.12/site-packages (from google-cloud-storage) (2.25.1)\n",
      "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.2 in ./.venv/lib/python3.12/site-packages (from google-cloud-storage) (2.4.3)\n",
      "Requirement already satisfied: google-resumable-media<3.0.0,>=2.7.2 in ./.venv/lib/python3.12/site-packages (from google-cloud-storage) (2.7.2)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.22.0 in ./.venv/lib/python3.12/site-packages (from google-cloud-storage) (2.32.5)\n",
      "Requirement already satisfied: google-crc32c<2.0.0,>=1.1.3 in ./.venv/lib/python3.12/site-packages (from google-cloud-storage) (1.7.1)\n",
      "Requirement already satisfied: scipy>=1.8.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.16.2)\n",
      "Requirement already satisfied: joblib>=1.2.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in ./.venv/lib/python3.12/site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in ./.venv/lib/python3.12/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in ./.venv/lib/python3.12/site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: starlette<0.49.0,>=0.40.0 in ./.venv/lib/python3.12/site-packages (from fastapi) (0.48.0)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in ./.venv/lib/python3.12/site-packages (from fastapi) (2.11.9)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in ./.venv/lib/python3.12/site-packages (from fastapi) (4.15.0)\n",
      "Requirement already satisfied: click>=7.0 in ./.venv/lib/python3.12/site-packages (from uvicorn) (8.2.1)\n",
      "Requirement already satisfied: h11>=0.8 in ./.venv/lib/python3.12/site-packages (from uvicorn) (0.16.0)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in ./.venv/lib/python3.12/site-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (1.70.0)\n",
      "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in ./.venv/lib/python3.12/site-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (6.32.1)\n",
      "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in ./.venv/lib/python3.12/site-packages (from google-api-core<3.0.0,>=2.15.0->google-cloud-storage) (1.26.1)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in ./.venv/lib/python3.12/site-packages (from google-auth<3.0.0,>=2.26.1->google-cloud-storage) (4.9.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.2 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.2)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in ./.venv/lib/python3.12/site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.1)\n",
      "Requirement already satisfied: six>=1.5 in ./.venv/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./.venv/lib/python3.12/site-packages (from requests<3.0.0,>=2.22.0->google-cloud-storage) (2025.8.3)\n",
      "Requirement already satisfied: anyio<5,>=3.6.2 in ./.venv/lib/python3.12/site-packages (from starlette<0.49.0,>=0.40.0->fastapi) (4.10.0)\n",
      "Requirement already satisfied: sniffio>=1.1 in ./.venv/lib/python3.12/site-packages (from anyio<5,>=3.6.2->starlette<0.49.0,>=0.40.0->fastapi) (1.3.1)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in ./.venv/lib/python3.12/site-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.26.1->google-cloud-storage) (0.6.1)\n"
     ]
    }
   ],
   "source": [
    "# Install required packages\n",
    "import sys\n",
    "!{sys.executable} -m pip install google-cloud-storage scikit-learn pandas numpy fastapi uvicorn python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846655e9",
   "metadata": {},
   "source": [
    "# Import Required Libraries and Setup GCP Authentication\n",
    "\n",
    "We'll now import the necessary libraries and set up GCP authentication. Make sure you have your GCP credentials JSON file ready."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9b8aabd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import os\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from google.cloud import storage\n",
    "from dotenv import load_dotenv\n",
    "from fastapi import FastAPI, HTTPException\n",
    "from pydantic import BaseModel\n",
    "import uvicorn\n",
    "import pickle\n",
    "\n",
    "# Load environment variables\n",
    "load_dotenv()\n",
    "\n",
    "# Set up GCP credentials\n",
    "os.environ['GOOGLE_APPLICATION_CREDENTIALS'] = os.getenv('GCP_CREDENTIALS_PATH')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ebf95c",
   "metadata": {},
   "source": [
    "# Data Processing and Cleaning\n",
    "\n",
    "Let's create functions for data processing and cleaning that will handle incoming data from GCP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7da7d9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataProcessor:\n",
    "    def __init__(self):\n",
    "        self.scaler = StandardScaler()\n",
    "        \n",
    "    def sanitize_input(self, data):\n",
    "        \"\"\"Remove invalid or missing values from the input data.\"\"\"\n",
    "        # Convert to DataFrame if not already\n",
    "        if not isinstance(data, pd.DataFrame):\n",
    "            data = pd.DataFrame(data)\n",
    "            \n",
    "        # Remove rows with missing values\n",
    "        data = data.dropna()\n",
    "        \n",
    "        # Remove duplicates\n",
    "        data = data.drop_duplicates()\n",
    "        \n",
    "        # Convert numeric columns to float\n",
    "        numeric_columns = data.select_dtypes(include=['int64', 'float64']).columns\n",
    "        data[numeric_columns] = data[numeric_columns].astype(float)\n",
    "        \n",
    "        return data\n",
    "    \n",
    "    def preprocess_data(self, data):\n",
    "        \"\"\"Scale and preprocess the input data.\"\"\"\n",
    "        # Separate features and target\n",
    "        X = data.drop('target', axis=1)\n",
    "        y = data['target']\n",
    "        \n",
    "        # Scale features\n",
    "        X_scaled = self.scaler.fit_transform(X)\n",
    "        \n",
    "        return pd.DataFrame(X_scaled, columns=X.columns), y\n",
    "\n",
    "# Initialize the data processor\n",
    "data_processor = DataProcessor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "370c085b",
   "metadata": {},
   "source": [
    "# GCP Integration\n",
    "\n",
    "Set up the GCP client and functions to handle data ingestion from Cloud Storage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98c66d09",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GCPHandler:\n",
    "    def __init__(self, bucket_name):\n",
    "        self.storage_client = storage.Client()\n",
    "        self.bucket_name = bucket_name\n",
    "        self.bucket = self.storage_client.bucket(bucket_name)\n",
    "    \n",
    "    def read_data_from_gcs(self, blob_name):\n",
    "        \"\"\"Read data from GCP Cloud Storage.\"\"\"\n",
    "        blob = self.bucket.blob(blob_name)\n",
    "        data = blob.download_as_string()\n",
    "        return pd.read_json(data)\n",
    "    \n",
    "    def upload_model_to_gcs(self, model, blob_name):\n",
    "        \"\"\"Upload trained model to GCP Cloud Storage.\"\"\"\n",
    "        blob = self.bucket.blob(blob_name)\n",
    "        with blob.open('wb') as f:\n",
    "            pickle.dump(model, f)\n",
    "\n",
    "# Initialize GCP handler\n",
    "gcp_handler = GCPHandler('demo-bucket-ml-pipeline')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e12a905",
   "metadata": {},
   "source": [
    "# Model Training\n",
    "\n",
    "Create and train the regression model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b9c4a85d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelTrainer:\n",
    "    def __init__(self):\n",
    "        self.model = LinearRegression()\n",
    "        \n",
    "    def train_model(self, X, y):\n",
    "        \"\"\"Train the regression model.\"\"\"\n",
    "        # Split data into train and test sets\n",
    "        X_train, X_test, y_train, y_test = train_test_split(\n",
    "            X, y, test_size=0.2, random_state=42\n",
    "        )\n",
    "        \n",
    "        # Train the model\n",
    "        self.model.fit(X_train, y_train)\n",
    "        \n",
    "        # Make predictions on test set\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        mse = mean_squared_error(y_test, y_pred)\n",
    "        r2 = r2_score(y_test, y_pred)\n",
    "        \n",
    "        print(f\"Model Performance:\")\n",
    "        print(f\"Mean Squared Error: {mse:.4f}\")\n",
    "        print(f\"R² Score: {r2:.4f}\")\n",
    "        \n",
    "        return self.model\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Make predictions using the trained model.\"\"\"\n",
    "        return self.model.predict(X)\n",
    "\n",
    "# Initialize model trainer\n",
    "model_trainer = ModelTrainer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc188d78",
   "metadata": {},
   "source": [
    "# FastAPI Integration\n",
    "\n",
    "Create FastAPI endpoints for model inference and dashboard data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a4d493f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define input data model\n",
    "class InputData(BaseModel):\n",
    "    features: dict\n",
    "\n",
    "# Create FastAPI app\n",
    "app = FastAPI(title=\"ML Model API\")\n",
    "\n",
    "@app.post(\"/predict\")\n",
    "async def predict(data: InputData):\n",
    "    try:\n",
    "        # Convert input data to DataFrame\n",
    "        input_df = pd.DataFrame([data.features])\n",
    "        \n",
    "        # Preprocess the input\n",
    "        input_df = data_processor.sanitize_input(input_df)\n",
    "        X_processed, _ = data_processor.preprocess_data(input_df)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = model_trainer.predict(X_processed)\n",
    "        \n",
    "        return {\"prediction\": float(prediction[0])}\n",
    "    \n",
    "    except Exception as e:\n",
    "        raise HTTPException(status_code=400, detail=str(e))\n",
    "\n",
    "@app.get(\"/model-info\")\n",
    "async def model_info():\n",
    "    \"\"\"Endpoint for dashboard to get model information.\"\"\"\n",
    "    return {\n",
    "        \"model_type\": \"Linear Regression\",\n",
    "        \"features\": list(data_processor.scaler.feature_names_in_),\n",
    "        \"model_parameters\": {\n",
    "            \"coefficients\": model_trainer.model.coef_.tolist(),\n",
    "            \"intercept\": float(model_trainer.model.intercept_)\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13aeae78",
   "metadata": {},
   "source": [
    "# Usage Example\n",
    "\n",
    "Let's see how to use this pipeline with some sample data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "01136ead",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Performance:\n",
      "Mean Squared Error: 0.0765\n",
      "R² Score: -0.0958\n",
      "Sample Prediction: 0.6031\n"
     ]
    }
   ],
   "source": [
    "# Create sample data\n",
    "sample_data = pd.DataFrame({\n",
    "    'feature1': np.random.random(100),\n",
    "    'feature2': np.random.random(100),\n",
    "    'feature3': np.random.random(100),\n",
    "    'target': np.random.random(100)\n",
    "})\n",
    "\n",
    "# Process data\n",
    "clean_data = data_processor.sanitize_input(sample_data)\n",
    "X_processed, y = data_processor.preprocess_data(clean_data)\n",
    "\n",
    "# Train model\n",
    "model = model_trainer.train_model(X_processed, y)\n",
    "\n",
    "# Make a sample prediction\n",
    "sample_input = {\n",
    "    \"features\": {\n",
    "        \"feature1\": 0.5,\n",
    "        \"feature2\": 0.3,\n",
    "        \"feature3\": 0.7\n",
    "    }\n",
    "}\n",
    "\n",
    "# Convert to DataFrame and preprocess\n",
    "input_df = pd.DataFrame([sample_input[\"features\"]])\n",
    "input_clean = data_processor.sanitize_input(input_df)\n",
    "\n",
    "# Scale the input using the fitted scaler (without target column)\n",
    "X_input = pd.DataFrame(data_processor.scaler.transform(input_clean), columns=input_clean.columns)\n",
    "\n",
    "# Get prediction\n",
    "prediction = model_trainer.predict(X_input)\n",
    "print(f\"Sample Prediction: {prediction[0]:.4f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
